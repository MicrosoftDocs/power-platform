---
title: "Use custom analytics reports"
description: "Guidance for extending the use and scope of analytics data in Power Virtual Agents by using a custom report template. Use your data with Dataverse, Azure data lake storage, and Power BI."
author: athinesh
ms.date: 5/11/2023
ms.topic: conceptual
ms.custom: guidance
ms.author: athinesh
ms.reviewer: iawilt
ms.collection: virtual-agent
---

# Custom analytics strategy


Power Virtual Agents provides comprehensive [out-of-the-box analytics](/power-virtual-agents/preview/analytics-overview) that allow customers to understand a bot's usage and key performance indicators.

Customers can view reports related to:

- Performance and usage.
- Customer satisfaction.
- Session information.
- Topic usage.
- Billed sessions.

However, there are often scenarios where you'll need to create or use custom analytics. For example, you may need to:

- Share analytics with non-makers or users.
- Report on conversation transcripts data for a period longer than the default last 30 days.
- Design a report not covered by out-of-the-box analytics.

There are a few ways you can take the analytics data recorded by Power Virtual Agents and use it in customized reports. 

## Power Virtual Agents analytics sample template report

To create custom analytics, our recommended approach is to start with the [Power Virtual Agents analytics sample template report](https://aka.ms/PVAAnalytics).
The sample template report is a set of open-source assets, distributed through GitHub, greatly accelerating the time it takes to create a report that renders in Power BI.

> [!WARNING]
> The solution is not part of the core Power Virtual Agents offering and will require configuration. 
>   
> The sample report is not supported by Microsoft, but you can raise issues in the GitHub repository to get help from the community.

### Dataverse

#### Conversation transcripts data

The analytics shown in the Power Virtual Agents portal come from a data service residing within Power Virtual Agents. Usage data is also written to the associated Dataverse environment, in the [conversation transcripts](/power-virtual-agents/analytics-sessions-transcripts) table.

#### Retention periods

By default, both sources have a data retention of 30 days, but customers can [change the retention period for conversation transcripts in Dataverse](/power-virtual-agents/analytics-sessions#change-the-default-period-of-session-transcript-retention).

#### Power Virtual Agents Dataverse tables

Power Virtual Agents uses the following tables for custom analytics in Dataverse:

- [**Chatbot**](/power-apps/developer/data-platform/reference/entities/bot) (`Bot`). This table includes details of each bot in an environment. Generally this is a small amount of data.
- [**Chatbot Subcomponent**](/power-apps/developer/data-platform/reference/entities/botcomponent) (`BotComponent`). This table lists the topics, entities, and dialogs associated with the bot in your environment. Generally this is a small amount of data.
- [**Conversation Transcripts**](/power-apps/developer/data-platform/reference/entities/conversationtranscript) (`ConversationTranscript`). This table contains detailed conversation data for all the chatbots in your environment. The size of the data in this table is related to the use of the bot and can be large.

### Azure Synapse Link for Dataverse (Azure Data Lake Storage Gen2)

When bots generate large volumes of conversation transcripts (roughly more than 10,000 sessions a month, representing more than 80 MB of transcript data), the recommended approach is to export bot data to an Azure Data Lake Storage Gen2 using the [Azure Synapse Link for Dataverse feature](/power-apps/maker/data-platform/export-to-data-lake). This approach has the benefit of offloading data from Dataverse database storage in a cheaper data lake storage. It also retains large volumes of conversation transcripts for long periods.

The export creates an incremental sync of configured Dataverse tables in the Azure data lake, using the Common Data Model format.

There are additional steps you'll need to take in addition to what is configured in the base template:

- [Create an Azure Data Lake Storage Gen2 and connect it to Dataverse](/power-apps/maker/data-platform/azure-synapse-link-synapse).
- During configuration, select the *ConversationTranscript* table (_Chatbot_ and _Chatbot Subcomponent_ don't support incremental sync).
- [Follow the guidance](https://github.com/microsoft/PowerVirtualAgentsSamples/tree/master/CustomAnalytics/DataFlowVersion) for setting up Power BI dataflows to process the incoming data.

> [!WARNING]
> By default, Azure Synapse Link for Dataverse mirrors the configured table data from Dataverse to the Azure data lake. Therefore, any record that gets deleted in Dataverse (for example, by the recurring bulk delete job that deletes conversation transcripts older than 30 days by default) will also be removed from the Azure data lake. To work around this, you can create copies or snapshots of your data in the Azure data lake, or you can configure the synchronization to use the [append-only mode](/power-apps/maker/data-platform/azure-synapse-link-advanced-configuration#in-place-updates-vs-append-only-writes).

### Power BI

The custom analytics solution template includes a Power BI report that processes the raw transcript data (using Power Query) into a report that matches the Power Virtual Agents default analytics.

In addition, users of the report have access to:

- Data for all chatbots in an environment.
- Data as far back as the feed provides (in Dataverse or in the Azure Data Lake Storage Gen2).
- Raw data tables extracted from the Conversation Transcript table data â€“ which can be used to create custom reports.
- A transcript viewer, allowing users to see the actual conversations that occurred.

> [!WARNING]
> This a complex report that performs significant transformations on the base data. Customers with Conversation Transcript tables greater than 80 MB should look to use the Azure Synapse Link for Dataverse and Power BI dataflows version of the report.

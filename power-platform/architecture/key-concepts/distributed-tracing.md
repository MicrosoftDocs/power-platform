---
title: Distributed tracing across multiple services​ in Power Platform
description: Learn how to trace events across multiple Power Platform services using distributed tracing for comprehensive observability.
#customer intent: As a Power-Platform user, I want to trace events that occur across multiple services in my Power Platform solution.
author: manuelap-msft
ms.subservice: architecture-center
ms.topic: example-scenario
ms.date: 03/24/2025
ms.author: mapichle
ms.reviewer: pankajsharma2087
contributors:
  - manuelap-msft
ms.contributors:
  - grarchib
search.audienceType:
  - admin
  - flowmaker
---

# ​​Distributed tracing across multiple services​ in Power Platform

This article explains how to achieve comprehensive observability across multiple services, including those within Power Platform, Azure, and Dynamics 365.

Monitoring tools and processes are essential for maintaining the health and performance of applications and services. They help in tracking metrics, logs, and traces to identify issues and optimize performance. [Azure Monitor](/azure/azure-monitor/fundamentals/overview) is a comprehensive solution for collecting, analyzing, and acting on telemetry from your cloud and on-premises environments. It uses [Kusto Query Language (KQL)](/kusto/query/) to query and correlate telemetry data across different components. Monitoring tools and processes are a well understood pattern. [Create KQL queries to query and correlate telemetry across different components](/azure/aks/monitor-aks?tabs=cilium) and [Query data in Azure Monitor with Azure Data Explorer](/azure/data-explorer/query-monitor-data) demonstrate how to add and query generated monitoring data. This pattern builds upon existing methods to achieve comprehensive observability across multiple services, including those within Power Platform, Azure, and Dynamics 365.

> [!TIP]
> The article provides an example scenario and visual representation of how to trace events across multiple services. This solution is a generalized example scenario architecture, which can be used for many different scenarios and industries.

## Architecture diagram

:::image type="content" source="./media/distributed-tracing/distributed-tracing.png" alt-text="Architecture diagram of distributed tracing across multiple Power Platform services. " lightbox="./media/distributed-tracing/distributed-tracing.png":::

## Workflows

Following are the steps for Azure to Dataverse web API workflow:

1. **​​End user applications**: Azure services and solutions like Azure Functions, web services and Kubernetes can start a distributed transaction relating to a specific event generated by the user or an agent.
1. **​Dataverse web API**: Azure services can add a W3C trace parent to requests to Dataverse entities and custom APIs. This trace parent can be included in the body of the request or in the tag query string of the request.
1. **​Dataverse messages**: Requests sent to Dataverse are sent as messages. These messages could relate to an entity or a custom defined API. Messages can have pre and post actions applied to them. These actions could be an Application Insights distributed tracking. 
1. **​Plugins**: Use Dataverse C# Plugin to generate distributed tracing telemetry to relate the Azure request to Dataverse action. 
1. **​Azure Monitor**: Create KQL queries to query and correlate telemetry across different components.

Following are the steps for ​Power Platform workflow: 

1. **​Instrument**: Configure the Power Platform resource with the Application Insights connection string / key 
1. **Trace**: Microsoft Copilot Studio, Power Apps, and Power Automate can begin a transaction by calling a custom Dataverse API.​ 

## Components

- **[​Application Insights](/azure/azure-monitor/app/app-insights-overview)**: Application Insights is a feature of [Azure Monitor](/azure/azure-monitor/overview), an extensible application performance management (APM) tool that allows you to monitor your live applications. It requires a subscription to [Microsoft Azure](https://azure.microsoft.com/). Application Insights is used for storing trace and dependency information, and enables searching for operation IDs.
- **​​Azure services**: [Observe Azure resources with Azure Monitor](/azure/azure-monitor/app/app-insights-overview). While resources from different Azure services have different monitoring requirements, they generate monitoring data in the same formats so that you can use the same Azure Monitor tools to analyze all Azure resources.
- **[​Copilot Studio](/microsoft-copilot-studio/fundamentals-what-is-copilot-studio)**: You can [capture telemetry data from your Copilot Studio agent](/microsoft-copilot-studio/advanced-bot-framework-composer-capture-telemetry?tabs=webApp) for use in Application Insights. To connect your agent to Application Insights, you first need to [add your instrumentation key to your agent's configuration](/microsoft-copilot-studio/advanced-bot-framework-composer-capture-telemetry?tabs=webApp#connect-your-copilot-studio-agent-to-application-insights). You can call an Environment Custom API from your agent to start a distributed transaction.
- **[​Power Apps canvas apps](/power-apps/maker/canvas-apps/)**: You can [connect your canvas apps to Application Insights](/power-apps/maker/canvas-apps/application-insights). You can call an environment custom API from your canvas app to start a distributed transaction.
- **[​Power Apps model-driven apps](/power-apps/maker/model-driven-apps/)**: You can [set up an Application Insights environment](/power-platform/admin/analyze-telemetry) to receive telemetry on diagnostics and performance captured by the Dataverse platform. You can subscribe to receive telemetry about operations that applications perform on your Dataverse database and within model-driven apps. You can call an environment custom API to start a distributed transaction.
- **[​Power Automate](/power-automate/)**: You can [enable export of cloud flow telemetry data](/power-platform/admin/app-insights-cloud-flow) to Application Insights at the environment. You can pass a distributed trace ID from Microsoft Copilot Studio or Power Apps to a cloud flow.
- **[Microsoft ​Dataverse](/power-apps/maker/data-platform/data-platform-intro)**: You can [set up an Application Insights environment](/power-platform/admin/analyze-telemetry) to receive telemetry on diagnostics and performance captured by the Dataverse platform.
- **[​Dataverse plug-ins](/power-apps/developer/data-platform/plug-ins)**: You can use C# Dataverse plugins to provide dependency records and integrate with Application Insights.
- **[​Azure Data Explorer](/azure/data-explorer/data-explorer-overview)**: You can use Azure Data Explorer to use KQL queries to join data across multiple sources.
- **[Power BI](/power-bi/)**: You can visualize and query telemetry data​ with Power BI.

## Scenario details

​​This architecture is designed to allow telemetry to be correlated across multiple components within the Power Platform and from systems outside the Power Platform by implementing the [W3C Distributed Tracing](https://www.w3.org/TR/trace-context/) standard so that:

- ​Allow trace and request records in Application Insights to be correlated using dependency records.
- Allow end to end traceability of operations.
- ​Allow support teams to configure telemetry to diagnose and resolve issues.
- ​Demonstrate how external systems can pass distributed tracing context to the Power Platform.
- ​Demonstrate how Power Platform components can be part of a distributed tracing session.​

### Distributed tracing

Distributed tracing is a method used to profile and monitor applications, especially those built using a microservices architecture. It allows you to trace an event in the system from one service to another and retrieve end-to-end diagnostics about performance and latency. The [W3C TraceContext](https://www.w3.org/TR/trace-context/) standard defines how context information is sent and modified between services, enabling distributed tracing scenarios.

#### Trace ID and Span ID

In the W3C TraceContext standard, each trace is assigned a globally unique 16-byte trace-ID, and every activity within the trace is assigned a unique 8-byte span-ID. The trace-ID represents the overall transaction, while the span-ID represents individual operations within that transaction. Each activity records the trace-ID, its own span-ID, and the span-ID of its parent, establishing parent-child relationships between activities.

#### Example Scenario

Let's consider an example where a browser starts a transaction, multiple microservices interact, and a call is made to the Dataverse web API

| Source | Trace ID and Span ID |
| --- | --- |
| Browser | trace parent: 00-11111111111111111111111111111111-2222222222222222-01 |
| Kubernetes | trace parent: 00-11111111111111111111111111111111-3333333333333333-01 |
| Dataverse | trace parent: 00-11111111111111111111111111111111-4444444444444444-01 |

1. **Browser initiates transaction**: The browser sends a request to a web server. This request is assigned a trace-ID and a span-ID (let's call it span-ID-1).
1. **Microservices interaction**: The web server processes the request and makes a call to a microservice. This call is assigned a new span-ID (span-ID-2) but retains the same trace-ID. The microservice, in turn, calls another microservice, creating another span-ID (span-ID-3), and so on.
1. **Call to Dataverse web API**: One of the microservices makes a call to the Dataverse Web API. This call is assigned a new span-ID (span-ID-4) but retains the same trace-ID.

#### Trace ID and parent-child relationship

The trace-ID is used to join all transactions with a parent-child relationship. Each span-ID represents a unique operation within the trace, and the parent span-ID links it to its parent operation. This hierarchical structure allows you to trace the entire transaction from the initial request to the final response, even as it traverses multiple services and systems.

#### Trace ID and operation ID lookup

The W3C TraceId field is mapped in Application Insights to the operation ID. This allows you to easily query a set of related actions that occur as part of the end to end trace.

:::image type="content" source="media/distributed-tracing/trace-id-field.png" alt-text="Screenshot of the Operation ID field mapped in Application Insights. " lightbox="media/distributed-tracing/trace-id-field.png":::

#### Practical applications and benefits

Using the W3C TraceContext standard for distributed tracing offers several practical applications and benefits:

1. End-to-end visibility: It provides end-to-end visibility into the transaction, helping you understand how requests propagate through your system.
1. Performance monitoring: It allows you to monitor the performance of individual services and identify bottlenecks.
1. Error diagnosis: It helps in diagnosing errors by tracing the path of a request and identifying where failures occur.
1. Dependency tracking: It enables you to track dependencies between services and understand how they interact.

By implementing distributed tracing with the W3C TraceContext standard, you can gain valuable insights into your application's behavior, improve performance, and enhance the overall user experience.

### Potential use cases

| Example | Description | Notes |
| --- | --- |--- |
| Autonomous agent | An autonomous agent is triggered by a data event. The possible long-lived transaction persists the trace parent. This transaction could cross multiple processes and services including possible handoff to a customer service agent. | Power Automate can request distributed tracing from Dataverse Plugin. Each step of the process adds Application Insights telemetry. E2E transaction could be queried in Application Insights or via KQL queries. |
| End user web, mobile, or agent transaction | A user starts a transaction to update their customer data. Trace entries are added to Application Insights from the request and trace messages from Dataverse | Kubernetes service starts a distributed transaction. It calls the Dataverse web API to update customer details. |
| Customer support agent | End customer contacts the call center. A call center operator makes use of Copilot and Power App to update the customer details. Each component in the update writes to Application Insights | Transaction starts with call center operator. The Power App requests distributed transaction from Dataverse. |

## Considerations

[!INCLUDE [pp-arch-ppwa-link](../../includes/pp-arch-ppwa-link.md)]

### Reliability

Ensure that the implemented solution fits into your [monitoring and alerting strategy](/power-platform/well-architected/performance-efficiency/collect-performance-data).

### Operational Excellence

To effectively monitor your workload for security, performance, and reliability, you need a comprehensive system with its own stack that provides the foundation for all monitoring, detection, and alerting functions. Learn more: [recommendations for designing and creating a monitoring system](/power-platform/well-architected/operational-excellence/observability)

#### Performance Efficiency

The suggestions in this example scenario allow you to [collect workload performance data recommendation for Power Platform workloads](/power-platform/well-architected/performance-efficiency/collect-performance-data)

## Next steps

> [!div class="nextstepaction"]
> [Learn how to implement distributed tracing](distributed-tracing-details.md)

## Contributors

_Microsoft maintains this article. The following contributors wrote this article._

Principal authors:

- **[Grant Archibald](https://www.linkedin.com/in/grantarchibald/)**, Senior Program Manager

## Related resources

- [W3C ​​Trace Context standard defining trace parent and tracestate HTTP headers](https://www.w3.org/TR/trace-context/)
- [​Event Framework (Microsoft Dataverse)](/power-apps/developer/data-platform/event-framework)
- [​Understand the execution context (Microsoft Dataverse)](/power-apps/developer/data-platform/understand-the-data-context#passing-a-shared-variable-from-the-api)
